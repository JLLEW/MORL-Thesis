{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "dqn_c = \"models/DQN_crypto_81_06_17_24_ca8svpca/evaluation_metrics_for_anova\"\n",
    "ppo_c = \"models/PPO_crypto_83_06_17_24_gzsbryxw/evaluation_metrics_for_anova\"\n",
    "pcn_c = \"models/PCN_sweep_sp_81_tlhm6t79_tlhm6t79/evaluation_metrics_for_anova\"\n",
    "\n",
    "paths = [pcn_c, dqn_c, ppo_c]\n",
    "output = []\n",
    "\n",
    "for p in paths:\n",
    "    main_path = p\n",
    "    results_df = pd.DataFrame(columns=['Episode return', 'Maximal drawdown', 'Volatility', 'Sharpe Ratio', 'Calmar Ratio', 'Ulcer index', 'Transaction costs'])\n",
    "\n",
    "    for i in range(30):\n",
    "        path = f\"{main_path}{i}.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        df['portfolio return'] = df['portfolio value'].pct_change().fillna(0)\n",
    "        initial_investment = df.loc[0, 'portfolio value']\n",
    "        df['cumulative portfolio return'] = (1 + df['portfolio return']).cumprod()\n",
    "        # generate metrics\n",
    "        df['daily_return'] = df['portfolio value'].pct_change()\n",
    "        # Final Return\n",
    "        final_return = df['portfolio value'].iloc[-1] / df['portfolio value'].iloc[0] - 1\n",
    "        # Maximal Drawdown\n",
    "        cumulative_return = (1 + df['daily_return']).cumprod()\n",
    "        rolling_max = cumulative_return.cummax()\n",
    "        drawdown = cumulative_return / rolling_max - 1\n",
    "        max_drawdown = drawdown.min()\n",
    "        # Average Volatility (annualized)\n",
    "        avg_volatility = df['daily_return'].std() * np.sqrt(252)  # 252 trading days in a year\n",
    "        # Sharpe Ratio\n",
    "        risk_free_rate = 0.01  # Assuming a risk-free rate of 1%\n",
    "        excess_return = df['daily_return'].mean() - (risk_free_rate / 252)\n",
    "        sharpe_ratio = excess_return / df['daily_return'].std() * np.sqrt(252)\n",
    "        # Calmar Ratio\n",
    "        calmar_ratio = excess_return / abs(max_drawdown)\n",
    "        # Ulcer index\n",
    "        drawdown_squared = drawdown**2\n",
    "        ulcer_index = np.sqrt(np.mean(drawdown_squared))\n",
    "\n",
    "        transaction_costs = df['transaction costs'].sum()/initial_investment\n",
    "\n",
    "        results_df.loc[i] = [final_return, max_drawdown, avg_volatility, sharpe_ratio, calmar_ratio, ulcer_index, transaction_costs]\n",
    "    output.append(copy.deepcopy(results_df))\n",
    "\n",
    "lengths = [\"PCN\", \"DQN\", \"PPO\"]\n",
    "for i, l in enumerate(lengths):\n",
    "    output[i]['model'] = l\n",
    "df1, df2, df3 = output\n",
    "df_combined = pd.concat([df1, df2, df3])\n",
    "df_combined.groupby('model').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "# Example for final return\n",
    "f_stat, p_val = f_oneway(df1['Episode return'], df2['Episode return'], df3['Episode return'])\n",
    "print(f'ANOVA result for Episode return: F-statistic={f_stat}, p-value={p_val}')\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "\n",
    "# Combine the data into one DataFrame for Tukey's HSD\n",
    "combined_data = pd.concat([df1.assign(Strategy='PCN'),\n",
    "                           df2.assign(Strategy='DQN'),\n",
    "                           df3.assign(Strategy='PPO')])\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=combined_data['Episode return'], groups=combined_data['Strategy'], alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ep_30 = \"models/PCN_sweep_sp_17_9s2d0yaa_9s2d0yaa/evaluation_metrics_front.csv\"\n",
    "ep_100 = \"models/PCN_sweep_sp_17_y73vig0d_y73vig0d/evaluation_metrics_front.csv\"\n",
    "ep_252 = 'models/PCN_sweep_sp_17_vxj8pdbw_vxj8pdbw/evaluation_metrics_front.csv'\n",
    "ep_30 = \"models/PCN_sweep_sp_17_9s2d0yaa_9s2d0yaa/evaluation_metrics_backtest.csv\"\n",
    "ep_100 = \"models/PCN_sweep_sp_17_y73vig0d_y73vig0d/evaluation_metrics_backtest.csv\"\n",
    "ep_252 = 'models/PCN_sweep_sp_17_vxj8pdbw_vxj8pdbw/evaluation_metrics_backtest.csv'\n",
    "ep_30 = \"models/PCN_sweep_sp_17_9s2d0yaa_9s2d0yaa/evaluation_metrics_front.csv\"\n",
    "ep_100 = \"models/PCN_sweep_sp_17_y73vig0d_y73vig0d/evaluation_metrics_front.csv\"\n",
    "ep_252 = 'models/PCN_sweep_sp_17_vxj8pdbw_vxj8pdbw/evaluation_metrics_front.csv'\n",
    "# ep_30 = \"models/PCN_sweep_sp_17_9s2d0yaa_9s2d0yaa/evaluation_metrics_backtest_validation.csv\"\n",
    "# ep_100 = \"models/PCN_sweep_sp_17_y73vig0d_y73vig0d/evaluation_metrics_backtest_validation.csv\"\n",
    "# ep_252 = 'models/PCN_sweep_sp_17_vxj8pdbw_vxj8pdbw/evaluation_metrics_backtest_validation.csv'\n",
    "df = pd.read_csv(ep_30)\n",
    "df2 = pd.read_csv(ep_100)\n",
    "df3 = pd.read_csv(ep_252)\n",
    "\n",
    "\n",
    "stocks = ['AAPL', 'MSFT', 'JNJ', 'PG', 'TSLA', 'NFLX', 'KO', 'V']\n",
    "stocks = [x+\" price\" for x in stocks]\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df[f\"{stock}_return\"] = df[stock].pct_change().fillna(0)\n",
    "\n",
    "df[\"market_return\"] = df[returns].mean(axis=1)\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df['cumulative portfolio return'] = (1 + df['market_return']).cumprod()\n",
    "# Calculate the portfolio value over time\n",
    "df['market value'] = initial_investment * df['cumulative portfolio return']\n",
    "# df['portfolio volatility'] = abs(df['risk reward'])\n",
    "\n",
    "date_range = pd.date_range(start='2020-08-24', periods=len(df), freq='B')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(date_range, df['portfolio value'], label='30-days episode based strategy')\n",
    "plt.plot(date_range, df2['portfolio value'], label='100-days episode based strategy')\n",
    "plt.plot(date_range, df3['portfolio value'], label='252-days episode based strategy')\n",
    "plt.plot(date_range, df['market value'], label='Baseline', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.title('Portfolio value for different episode length configurations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(df['transaction costs'].sum())\n",
    "print(df2['transaction costs'].sum())\n",
    "print(df3['transaction costs'].sum())\n",
    "print(df2['actions'].value_counts())\n",
    "print(df['AAPL price'].tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pct\"] = df[\"portfolio value\"].pct_change().fillna(0)\n",
    "df2[\"pct\"] = df2[\"portfolio value\"].pct_change().fillna(0)\n",
    "df3[\"pct\"] = df3[\"portfolio value\"].pct_change().fillna(0)\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example for final return\n",
    "f_stat, p_val = f_oneway(df['pct'], df2['pct'], df3['pct'])\n",
    "print(f'ANOVA result for pct returns: F-statistic={f_stat}, p-value={p_val}')\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# Example for final return using the Kruskal-Wallis test\n",
    "posthoc = sp.posthoc_dunn([df['pct'], df2['pct'], df3['pct']], p_adjust='bonferroni')\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "ep_30 = \"models/PCN_sweep_sp_17_9s2d0yaa_9s2d0yaa/evaluation_metrics_for_anova_side\"\n",
    "ep_100 = \"models/PCN_sweep_sp_17_y73vig0d_y73vig0d/evaluation_metrics_for_anova_side\"\n",
    "ep_252 = 'models/PCN_sweep_sp_17_vxj8pdbw_vxj8pdbw/evaluation_metrics_for_anova_side'\n",
    "\n",
    "paths = [ep_30, ep_100, ep_252]\n",
    "output = []\n",
    "\n",
    "for p in paths:\n",
    "    main_path = p\n",
    "    results_df = pd.DataFrame(columns=['Final Return', 'Maximal Drawdown', 'Volatility', 'Sharpe Ratio', 'Calmar Ratio', 'Ulcer index', 'Transaction costs'])\n",
    "\n",
    "    for i in range(30):\n",
    "        path = f\"{main_path}{i}.csv\"\n",
    "        df = pd.read_csv(path)\n",
    "        stocks = ['AAPL', 'MSFT', 'JNJ', 'PG', 'TSLA', 'NFLX', 'KO', 'V']\n",
    "        stocks = [x+\" price\" for x in stocks]\n",
    "        returns = []\n",
    "        for stock in stocks:\n",
    "            returns = [f\"{stock}_return\"]\n",
    "            df[f\"{stock}_return\"] = df[stock].pct_change().fillna(0)\n",
    "        df[\"market_return\"] = df[returns].mean(axis=1)\n",
    "        initial_investment = df.loc[0, 'portfolio value']\n",
    "        df['cumulative portfolio return'] = (1 + df['market_return']).cumprod()\n",
    "        # Calculate the portfolio value over time\n",
    "        df['market value'] = initial_investment * df['cumulative portfolio return']\n",
    "        # generate metrics\n",
    "        df['daily_return'] = df['market value'].pct_change()\n",
    "        # Final Return\n",
    "        final_return = df['market value'].iloc[-1] / df['market value'].iloc[0] - 1\n",
    "        # Maximal Drawdown\n",
    "        cumulative_return = (1 + df['daily_return']).cumprod()\n",
    "        rolling_max = cumulative_return.cummax()\n",
    "        drawdown = cumulative_return / rolling_max - 1\n",
    "        max_drawdown = drawdown.min()\n",
    "        # Average Volatility (annualized)\n",
    "        avg_volatility = df['daily_return'].std() * np.sqrt(252)  # 252 trading days in a year\n",
    "        # Sharpe Ratio\n",
    "        risk_free_rate = 0.01  # Assuming a risk-free rate of 1%\n",
    "        excess_return = df['daily_return'].mean() - (risk_free_rate / 252)\n",
    "        sharpe_ratio = excess_return / df['daily_return'].std() * np.sqrt(252)\n",
    "        # Calmar Ratio\n",
    "        calmar_ratio = excess_return / abs(max_drawdown)\n",
    "        # Ulcer index\n",
    "        drawdown_squared = drawdown**2\n",
    "        ulcer_index = np.sqrt(np.mean(drawdown_squared))\n",
    "\n",
    "        transaction_costs = df['transaction costs'].sum()/initial_investment\n",
    "\n",
    "        results_df.loc[i] = [final_return, max_drawdown, avg_volatility, sharpe_ratio, calmar_ratio, ulcer_index, transaction_costs]\n",
    "\n",
    "    #transaction_costs/=initial_investment\n",
    "    output.append(copy.deepcopy(results_df))\n",
    "\n",
    "lengths = [30, 100, 252]\n",
    "for i, l in enumerate(lengths):\n",
    "    output[i]['episode length'] = l\n",
    "df1, df2, df3 = output\n",
    "df_combined = pd.concat([df1, df2, df3])\n",
    "df_combined.groupby('episode length').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "correlation, p_value = stats.pearsonr(df_combined['Final Return'], df_combined['episode length'])\n",
    "print(\"Pearson correlation coefficient:\", correlation)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sp_PCN_100_best = \"models/PCN_sweep_sp_57_xo7t4bkx_xo7t4bkx/evaluation_metrics.csv\"\n",
    "\n",
    "\n",
    "# PCN 100 new obs - does not change actions\n",
    "new_obs_sp = \"models/PCN_sweep_sp_17_oivusehp_oivusehp/evaluation_metrics.csv\"\n",
    "new_obs_sp_extended = \"models/PCN_sweep_sp_17_v0244b2c_v0244b2c/evaluation_metrics.csv\"\n",
    "dqn_100 = \"models/DQN_sp_extended_17_06_15_24_d8hah8u1/evaluation_metrics.csv\"\n",
    "ppo_100 = \"models/PPO_sp_extended_81_06_15_24_pcr0nder/evaluation_metrics.csv\"\n",
    "\n",
    "\n",
    "\n",
    "path = new_obs_sp_extended\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "stocks = ['AAPL',\n",
    "        'MSFT',\n",
    "        'JNJ',\n",
    "        'PG',\n",
    "        'TSLA',\n",
    "        'NFLX',\n",
    "        'KO',\n",
    "        'V',\n",
    "        'GOOGL',\n",
    "        'AMZN',\n",
    "        'META',\n",
    "        'JPM',\n",
    "        'UNH',\n",
    "        'HD',\n",
    "        'VZ',\n",
    "        'DIS',\n",
    "        'NVDA',\n",
    "        'MA',\n",
    "        'ADBE',\n",
    "        'IBM']\n",
    "stocks = [x+\" price\" for x in stocks]\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df[f\"{stock}_return\"] = df[stock].pct_change().fillna(0)\n",
    "\n",
    "df[\"market_return\"] = df[returns].mean(axis=1)\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df['cumulative market return'] = (1 + df['market_return']).cumprod()\n",
    "# Calculate the market value over time\n",
    "df['market value'] = initial_investment * df['cumulative market return']\n",
    "# df['portfolio volatility'] = abs(df['risk reward'])\n",
    "df.to_csv(path[:-4]+\"_processed.csv\")\n",
    "\n",
    "path = ppo_100\n",
    "\n",
    "df1 = pd.read_csv(path)\n",
    "\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df1[f\"{stock}_return\"] = df1[stock].pct_change().fillna(0)\n",
    "\n",
    "df1[\"market_return\"] = df1[returns].mean(axis=1)\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df1['cumulative market return'] = (1 + df1['market_return']).cumprod()\n",
    "# Calculate the market value over time\n",
    "df1['market value'] = initial_investment * df1['cumulative market return']\n",
    "# df['portfolio volatility'] = abs(df['risk reward'])\n",
    "df1.to_csv(path[:-4]+\"_1_processed.csv\")\n",
    "path = dqn_100\n",
    "df2 = pd.read_csv(path)\n",
    "\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df2[f\"{stock}_return\"] = df2[stock].pct_change().fillna(0)\n",
    "\n",
    "df2[\"market_return\"] = df2[returns].mean(axis=1)\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df2['cumulative market return'] = (1 + df2['market_return']).cumprod()\n",
    "# Calculate the market value over time\n",
    "df2['market value'] = initial_investment * df2['cumulative market return']\n",
    "# df['portfolio volatility'] = abs(df['risk reward'])\n",
    "df2.to_csv(path[:-4]+\"_2_processed.csv\")\n",
    "date_range = pd.date_range(start='2022-04-04', periods=len(df), freq='D')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(date_range, df['portfolio value'], label='PCN')\n",
    "plt.plot(date_range, df1['portfolio value'], label='PPO')\n",
    "plt.plot(date_range, df2['portfolio value'], label='DQN')\n",
    "plt.plot(date_range, df['market value'], label='Baseline', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.title('Portfolio value for S&P500 selected 20 stocks scenario')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back tests results on validation data\n",
    "pcn = \"models/PCN_sweep_sp_17_v0244b2c_v0244b2c/evaluation_metrics_backtest_validation.csv\"\n",
    "dqn = \"models/DQN_sp_extended_17_06_15_24_d8hah8u1/evaluation_metrics_backtest_validation.csv\"\n",
    "ppo = \"models/PPO_sp_extended_81_06_15_24_pcr0nder/evaluation_metrics_backtest_validation.csv\"\n",
    "df = pd.read_csv(pcn)\n",
    "df2 = pd.read_csv(dqn)\n",
    "df3 = pd.read_csv(ppo)\n",
    "\n",
    "\n",
    "stocks = ['AAPL',\n",
    "        'MSFT',\n",
    "        'JNJ',\n",
    "        'PG',\n",
    "        'TSLA',\n",
    "        'NFLX',\n",
    "        'KO',\n",
    "        'V',\n",
    "        'GOOGL',\n",
    "        'AMZN',\n",
    "        'META',\n",
    "        'JPM',\n",
    "        'UNH',\n",
    "        'HD',\n",
    "        'VZ',\n",
    "        'DIS',\n",
    "        'NVDA',\n",
    "        'MA',\n",
    "        'ADBE',\n",
    "        'IBM']\n",
    "stocks = [x+\" price\" for x in stocks]\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df[f\"{stock}_return\"] = df[stock].pct_change().fillna(0)\n",
    "\n",
    "df[\"market_return\"] = df[returns].mean(axis=1)\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df['cumulative portfolio return'] = (1 + df['market_return']).cumprod()\n",
    "# Calculate the portfolio value over time\n",
    "df['market value'] = initial_investment * df['cumulative portfolio return']\n",
    "# df['portfolio volatility'] = abs(df['risk reward'])\n",
    "\n",
    "date_range = pd.date_range(start='2020-08-24', periods=len(df), freq='B')\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(date_range, df['portfolio value'], label='PCN')\n",
    "plt.plot(date_range, df2['portfolio value']/10, label='DQN')\n",
    "plt.plot(date_range, df3['portfolio value']/10, label='PPO')\n",
    "plt.plot(date_range, df['market value'], label='Baseline', linestyle='--')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.title('Portfolio value for different episode length configurations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "pcn = \"models/PCN_sweep_sp_17_v0244b2c_v0244b2c/evaluation_metrics_backtest_validation.csv\"\n",
    "dqn = \"models/DQN_sp_extended_17_06_15_24_d8hah8u1/evaluation_metrics_backtest_validation.csv\"\n",
    "ppo = \"models/PPO_sp_extended_81_06_15_24_pcr0nder/evaluation_metrics_backtest_validation.csv\"\n",
    "\n",
    "stocks = ['AAPL',\n",
    "        'MSFT',\n",
    "        'JNJ',\n",
    "        'PG',\n",
    "        'TSLA',\n",
    "        'NFLX',\n",
    "        'KO',\n",
    "        'V',\n",
    "        'GOOGL',\n",
    "        'AMZN',\n",
    "        'META',\n",
    "        'JPM',\n",
    "        'UNH',\n",
    "        'HD',\n",
    "        'VZ',\n",
    "        'DIS',\n",
    "        'NVDA',\n",
    "        'MA',\n",
    "        'ADBE',\n",
    "        'IBM']\n",
    "for i in range(len(stocks)):\n",
    "    stocks[i] += \" price\"\n",
    "paths = [pcn, dqn, ppo]\n",
    "dfs = [pd.read_csv(path) for path in paths]\n",
    "df_baselines = copy.deepcopy(dfs[0])\n",
    "output = []\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df_baselines[f\"{stock}_return\"] = df_baselines[stock].pct_change().fillna(0)\n",
    "\n",
    "df_baselines[\"market_return\"] = df_baselines[returns].mean(axis=1)\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df_baselines['cumulative market return'] = (1 + df_baselines['market_return']).cumprod()\n",
    "# Calculate the market value over time\n",
    "df_baselines['market value'] = initial_investment * df_baselines['cumulative market return']\n",
    "df_baselines['portfolio value'] = df_baselines['market value']\n",
    "\n",
    "dfs.append(df_baselines)\n",
    "results_df = pd.DataFrame(columns=['Episode return', 'Maximal drawdown', 'Volatility', 'Sharpe Ratio', 'Calmar Ratio', 'Ulcer index', 'Transaction costs'])\n",
    "\n",
    "for df in dfs:\n",
    "\n",
    "    df['portfolio return'] = df['portfolio value'].pct_change().fillna(0)\n",
    "    initial_investment = df.loc[0, 'portfolio value']\n",
    "    df['cumulative portfolio return'] = (1 + df['portfolio return']).cumprod()\n",
    "    # Calculate the portfolio value over time\n",
    "    #market_return = df['market value'].iloc[-1] / df['market value'].iloc[0] - 1\n",
    "    # generate metrics\n",
    "    df['daily_return'] = df['portfolio value'].pct_change()\n",
    "    # Final Return\n",
    "    final_return = df['portfolio value'].iloc[-1] / df['portfolio value'].iloc[0] - 1\n",
    "    # Maximal Drawdown\n",
    "    cumulative_return = (1 + df['daily_return']).cumprod()\n",
    "    rolling_max = cumulative_return.cummax()\n",
    "    drawdown = cumulative_return / rolling_max - 1\n",
    "    max_drawdown = drawdown.min()\n",
    "    # Average Volatility (annualized)\n",
    "    avg_volatility = df['daily_return'].std() * np.sqrt(252)  # 252 trading days in a year\n",
    "    # Sharpe Ratio\n",
    "    risk_free_rate = 0.01  # Assuming a risk-free rate of 1%\n",
    "    excess_return = df['daily_return'].mean() - (risk_free_rate / 252)\n",
    "    sharpe_ratio = excess_return / df['daily_return'].std() * np.sqrt(252)\n",
    "    # Calmar Ratio\n",
    "    calmar_ratio = excess_return / abs(max_drawdown)\n",
    "    # Ulcer index\n",
    "    drawdown_squared = drawdown**2\n",
    "    ulcer_index = np.sqrt(np.mean(drawdown_squared))\n",
    "\n",
    "    transaction_costs = df['transaction costs'].sum()/initial_investment\n",
    "\n",
    "    results_df.loc[i] = [final_return, max_drawdown, avg_volatility, sharpe_ratio, calmar_ratio, ulcer_index, transaction_costs]\n",
    "    output.append(copy.deepcopy(results_df))\n",
    "\n",
    "lengths = [\"PCN\", \"DQN\", \"PPO\", \"Baseline\"]\n",
    "for i, l in enumerate(lengths):\n",
    "    output[i]['model'] = l\n",
    "df1, df2, df3, df4 = output\n",
    "df_combined = pd.concat([df1, df2, df3, df4])\n",
    "df_combined.groupby('model').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "dqn_c = \"models/DQN_crypto_81_06_17_24_ca8svpca/evaluation_metrics_backtest_validation.csv\"\n",
    "ppo_c = \"models/PPO_crypto_83_06_17_24_gzsbryxw/evaluation_metrics_backtest_validation.csv\"\n",
    "pcn_c = \"models/PCN_sweep_sp_81_tlhm6t79_tlhm6t79/evaluation_metrics_backtest_validation.csv\"\n",
    "df = pd.read_csv(dqn_c)\n",
    "df2 = pd.read_csv(ppo_c)\n",
    "df3 = pd.read_csv(pcn_c)\n",
    "\n",
    "\n",
    "stocks = [\"BTC-USD\", \"ETH-USD\", \"LTC-USD\", \"XRP-USD\", \"XMR-USD\", \n",
    "           \"DASH-USD\", \"ETC-USD\", \"ZEC-USD\", \"DCR-USD\", \"WAVES-USD\"]\n",
    "stocks = [x+\" price\" for x in stocks]\n",
    "\n",
    "paths = [pcn_c, dqn_c, ppo_c]\n",
    "dfs = [pd.read_csv(path) for path in paths]\n",
    "df_baselines = copy.deepcopy(dfs[0])\n",
    "output = []\n",
    "returns = []\n",
    "for stock in stocks:\n",
    "    returns = [f\"{stock}_return\"]\n",
    "    df_baselines[f\"{stock}_return\"] = df_baselines[stock].pct_change().fillna(0)\n",
    "\n",
    "df_baselines[\"market_return\"] = df_baselines[\"BTC-USD price_return\"]\n",
    "initial_investment = df.loc[0, 'portfolio value']\n",
    "df_baselines['cumulative market return'] = (1 + df_baselines['market_return']).cumprod()\n",
    "# Calculate the market value over time\n",
    "df_baselines['market value'] = initial_investment * df_baselines['cumulative market return']\n",
    "df_baselines['portfolio value'] = df_baselines['market value']\n",
    "\n",
    "dfs.append(df_baselines)\n",
    "results_df = pd.DataFrame(columns=['Episode return', 'Maximal drawdown', 'Volatility', 'Sharpe Ratio', 'Calmar Ratio', 'Ulcer index', 'Transaction costs'])\n",
    "\n",
    "for df in dfs:\n",
    "    # returns = []\n",
    "    # for stock in stocks:\n",
    "    #     returns = [f\"{stock}_return\"]\n",
    "    #     df[f\"{stock}_return\"] = df[stock].pct_change().fillna(0)\n",
    "\n",
    "    # df[\"market_return\"] = df[returns].mean(axis=1)\n",
    "    # initial_investment = df.loc[0, 'portfolio value']\n",
    "    # df['cumulative market return'] = (1 + df['market_return']).cumprod()\n",
    "    # # Calculate the market value over time\n",
    "    # df['market value'] = initial_investment * df['cumulative market return']\n",
    "\n",
    "    df['portfolio return'] = df['portfolio value'].pct_change().fillna(0)\n",
    "    initial_investment = df.loc[0, 'portfolio value']\n",
    "    df['cumulative portfolio return'] = (1 + df['portfolio return']).cumprod()\n",
    "    # Calculate the portfolio value over time\n",
    "    #market_return = df['market value'].iloc[-1] / df['market value'].iloc[0] - 1\n",
    "    # generate metrics\n",
    "    df['daily_return'] = df['portfolio value'].pct_change()\n",
    "    # Final Return\n",
    "    final_return = df['portfolio value'].iloc[-1] / df['portfolio value'].iloc[0] - 1\n",
    "    # Maximal Drawdown\n",
    "    cumulative_return = (1 + df['daily_return']).cumprod()\n",
    "    rolling_max = cumulative_return.cummax()\n",
    "    drawdown = cumulative_return / rolling_max - 1\n",
    "    max_drawdown = drawdown.min()\n",
    "    # Average Volatility (annualized)\n",
    "    avg_volatility = df['daily_return'].std() * np.sqrt(252)  # 252 trading days in a year\n",
    "    # Sharpe Ratio\n",
    "    risk_free_rate = 0.01  # Assuming a risk-free rate of 1%\n",
    "    excess_return = df['daily_return'].mean() - (risk_free_rate / 252)\n",
    "    sharpe_ratio = excess_return / df['daily_return'].std() * np.sqrt(252)\n",
    "    # Calmar Ratio\n",
    "    calmar_ratio = excess_return / abs(max_drawdown)\n",
    "    # Ulcer index\n",
    "    drawdown_squared = drawdown**2\n",
    "    ulcer_index = np.sqrt(np.mean(drawdown_squared))\n",
    "\n",
    "    transaction_costs = df['transaction costs'].sum()/initial_investment\n",
    "\n",
    "    results_df.loc[i] = [final_return, max_drawdown, avg_volatility, sharpe_ratio, calmar_ratio, ulcer_index, transaction_costs]\n",
    "    output.append(copy.deepcopy(results_df))\n",
    "\n",
    "lengths = [\"PCN\", \"DQN\", \"PPO\", \"Baseline\"]\n",
    "for i, l in enumerate(lengths):\n",
    "    output[i]['model'] = l\n",
    "df1, df2, df3, df4 = output\n",
    "df_combined = pd.concat([df1, df2, df3, df4])\n",
    "df_combined.groupby('model').mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
